
------------------- docs ------------------------

k8s podSpec guide:
	https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#pod-v1-core
	https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podspec-v1-core

	** Containers are only ever created within the context of a Pod. This is usually done using a Controller. See Controllers: Deployment, Job, or StatefulSet
	deployement controller:
		https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#deployment-v1-apps

Replicaset Guide:
	https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#replicaset-v1-apps


emptydir vs persistence volume:
	https://www.alibabacloud.com/blog/kubernetes-volume-basics-emptydir-and-persistentvolume_594834
	https://kubernetes.io/docs/concepts/storage/volumes/?spm=a2c65.11461447.0.0.37da3505crUBaD#types-of-volumes

------------------- Commands: --------------------



Persistent Volume (PV) and Persistent Volume Claim(PVC):
	kubectl get pv
	kubectl get pvc --namespace jenkins  
	kubectl --namespace jenkins delete deploy jenkins
	kubectl --namespace jenkins delete pvc jenkins
	kubectl delete -f pv/pv.yml
	
Creating User and Groups, Service Account(SA):
	
Switching context (user/namespace/cluster):
	* We can switch user/namespace/cluster by switching context, that configures (user, cluster, namespace)
		kubectl config view
		kubectl config current-context
		kubectl config use-context jdoe
		kubectl config set-context jdoe --cluster jdoe --user jdoe --namespace jdoe

		user and context creation:
		  kubectl config set-cluster jdoe --certificate-authority  /usercode/certs/keys/server-ca.crt --server $SERVER (create new cluster)
		  kubectl config set-credentials jdoe --client-certificate keys/jdoe.crt --client-key keys/jdoe.key (create user)
		  kubectl config set-context jdoe --cluster jdoe --user jdoe (create context)


Rolebinding and clusterrolebinding:
	* The rolebinding can bind a user (Group, SA)  to a Role or a Clusterroles in a given namespace.Since we used Role Binding, the scope is limited to a single Namespace which, in our case, is the default
	* This is a good moment to clarify that a Role Binding does not need to be used only with a Role, but that it can also be combined with a Cluster Role (as in our example). 
	* As the rule of thumb, we define Cluster Roles when we think that they might be used cluster-wide (with Cluster Role Bindings) or in multiple Namespaces.
	Grant cluster-wide access to the user with the help of ClusterRoleBindings. A user given a ClusterRole using ClusterRoleBinding will execute on those resource across namespaces 

	kubectl get rolebindings -n default
	kubectl get clusterrolebindings

Security:
	check k8s secure port:
		kubectl config view -o jsonpath='{.clusters[?(@.name=="k3d-mycluster")].cluster.server}'
		response: https://0.0.0.0:37141
 	check if RBAC is enabled:
 		kubectl api-versions

 	SERVER=$(kubectl config view -o jsonpath='{.clusters[?(@.name=="k3d-mycluster")].cluster.server}')	
 	
 	kubectl config set-cluster jdoe --certificate-authority /usercode/certs/keys/server-ca.crt --server $SERVER
	kubectl config set-credentials jdoe --client-certificate keys/jdoe.crt --client-key keys/jdoe.key
	kubectl config set-context jdoe --cluster jdoe --user jdoe
	kubectl config use-context jdoe
	kubectl config view
	kubectl get pods
	kubectl get all	

	Roles:
		kubectl auth can-i get pods --as jdoe (check if you can perform an operation)
		kubectl get roles
		kubectl get clusterroles
		kubectl get clusterroles | grep -v system
		kubectl describe clusterrole view
	 	kubectl auth can-i "*" "*"
	
	RoleBinding:
	 	kubectl create rolebinding jdoe --clusterrole view --user jdoe --namespace default  --save-config
	 	kubectl get rolebindings
		kubectl describe rolebinding jdoe
		kubectl --namespace kube-system describe rolebinding jdoe
		kubectl auth can-i get pods --as jdoe
		kubectl auth can-i get pods --as jdoe --all-namespaces
		kubectl delete rolebinding jdoe

	varification of roles:
		kubectl --namespace default auth can-i "*" pods --as jdoe
		kubectl --namespace default auth can-i create deployments --as jdoe
		kubectl --namespace default auth can-i delete deployments --as jdoe



namespace:
	- https://kubernetes.io/docs/reference/kubectl/cheatsheet/#kubectl-context-and-configuration

	kubectl create ns testing
	kubectl config set-context testing --namespace testing --cluster k3d-mycluster --user admin@k3d-mycluster
	kubectl config set-context k3d-mycluster --cluster k3d-mycluster --user admin@k3d-mycluster	
	kubectl config view
	kubectl config current-context 
	kubectl config use-context testing
	kubectl delete ns testing (deleting a namespace will delete all resource in that namespace)
	kubectl -n testing get all

	reaching across namespace:
		<service-name>.<namespace-name>.svc.cluster.local
			go-demo-2-api.testing
			go-demo-2-api.testing.svc.cluster.local
		kubectl exec -it test -- curl "http://go-demo-2-api.testing.svc.cluster:8080/demo/hello"
	
	* https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#namespace-v1-core

display format:
	-o yaml
	-o json


Secrets:
	kubectl create secret generic/docker-registry/tls my-creds --from-literal=username=jdoe --from-literal=password=incognito
	kubectl get secret my-creds -o json
	kubectl get secret my-creds -o jsonpath="{.data.username}" | base64 --decode

configmap:
	kubectl create cm my-config --from-file=prometheus-conf.yml	
	kubectl create cm my-config --from-file=cm/prometheus-conf.yml --from-file=cm/prometheus.yml (from multiple files)	
	kubectl create cm my-config --from-file=cm (from directory cm )
	kubectl delete cm my-config
	kubectl get cm my-config -o yaml
	kubectl create cm my-config --from-literal=something=else --from-literal=weather=sunny
	kubectl create cm my-config --from-env-file=my-env-file.yml

deployment details:
	kubectl get -f go-demo-2.yml ( get details of deployment, service etc)
	kubectl get deployments --show-labels
	kubectl get deployments -l type=db,vendor=MongoLabs
	kubectl --namespace default create deployment db --image mongo:3.3
	kubectl --namespace default delete deployment db

Run / Delete POD:
	kubectl run db --image mongo
	kubectl delete pod db
	kubectl delete -f go-demo-2.yml --cascade=orphan (delete only replica set not the pods)
	kubectl delete $POD_NAME

POD details:
	* get pods -o yaml (It provides details about pod spec, mount, volumes, metadata like podname) etc.
	kubectl create -f db.yml
	kubectl get pods
	kubectl get pods -o wide
	kubectl get pods -o json
	kubectl get pods -o yaml
	kubectl describe pod db	
	kubectl get events
	kubectl get -f go-demo-2.yml -o jsonpath="{.spec.containers[*].name}"
	kubectl get -f go-demo-2.yml -o json

POD run / delete / exec / describe:
	kubectl exec -it test -- apk add -U curl (add curl)
	kubectl exec -it alpine -- ls -l /etc/config  (directly executing command in a POD name alpine)
	kubectl describe -f db.yml
	kubectl exec db -- ps aux (short lived command execution)
	kubectl exec -it db -- sh (long lived command execution)
		echo 'db.stats()' | mongo localhost:27017/test
		exit
	kubectl logs -f db (-f : followup logs)
	kubectl exec db --  pkill mongod
	kubectl get pods
	kubectl delete -f db.yml 
	kubectl get pods
	kubectl run docker --image=docker:17.11  --restart=Never docker image ls	
	kubectl exec $POD_NAME -it -- kill 1 ( pod kill simulation )

POD describe:
	* It will provide container status, allocation, image pull status, Mounts, Volumes etc.
	kubectl describe -f db.yml
	kubectl describe pod <podName>
	kubectl exec db -- ps aux (run onetime command in containers of pod)
	echo 'db.stats()' | mongo localhost:27017/test (execute mongodb stats after connecting to mongo)

POD label:
	kubectl label $POD_NAME service-	      (delete label)
	kubectl label $POD_NAME service=go-demo-2 (add label)
	kubectl get pods --show-labels

replicaset:
	kubectl get rs (get replicate sets)	

service:
	exposing replicaset as service:
		kubectl expose rs go-demo-2 \
	    --name=go-demo-2-svc \
	    --target-port=28017 \
	    --type=NodePort

	describe service:
		kubectl describe svc/go-demo-2-svc
		kubectl get svc go-demo-2-api -o yaml

	service port forward:
		kubectl port-forward service/go-demo-2-api 3000:8080 --address 0.0.0.0
		curl -i "0.0.0.0:3000/demo/hello"

	sevice info:
		kubectl get svc go-demo-2-api -o yaml	

POD Name:
	POD_NAME=$(kubectl get pods -o name | tail -1)
	POD_NAME=$(kubectl get pods --no-headers -o=custom-columns=NAME:.metadata.name -l type=db,service=go-demo-2 | tail -1)	
	POD_NAME=$(kubectl get pods -l service=jenkins,type=master -o jsonpath="{.items[*].metadata.name}")

POD IP/port:
	IP=$(minikube ip)
	PORT=$(kubectl get svc go-demo-2-api -o jsonpath="{.spec.ports[0].nodePort}")
	curl -i "http://$IP:$PORT/demo/hello"

rolling update:
	kubectl create -f go-demo-2-api.yml --record
	kubectl set image -f go-demo-2-api.yml api=vfarcic/go-demo-2:2.0
	kubectl set image -f go-demo-2-db.yml db=mongo:3.4 --record (update image name db with new version)
	kubectl set image deployments -l type=db,vendor=MongoLabs db=mongo:3.4 --record ( update multiple objects)
	
	kubectl rollout status deployment go-demo-2-api (provides deployment status at realtime)
	kubectl rollout status deploy prometheus
	
	kubectl rollout history -f go-demo-2-api.yml
	kubectl rollout history deployment go-demo-2-api

scale replica:	
	kubectl scale deployment go-demo-2-api --replicas 8 --record


endpoint:
	kubectl get ep go-demo-2 -o yaml (describe endpoint)

port forwarding to service:
	- https://amalgjose.com/2021/06/08/how-to-configure-kubernetes-port-forward-bind-to-0-0-0-0-instead-of-default-127-0-0-1/
	- kubectl port-forward service/go-demo-2-svc 3000:28017 --address 0.0.0.0 
		* port-forward allows to access the service from external host through host-ip:3000
		* IP address 0.0. 0.0 is used on servers to designate a service may bind to all network interfaces.	
		* curl -H "Host: go-demo-2.com" http://0.0.0.0:3000/demo/hello
	- nohup kubectl port-forward service/go-demo-2-api --address 0.0.0.0  3000:8080 > /dev/null 2>&1 &	    
	- nohup kubectl port-forward -n ingress-nginx service/ingress-nginx-controller 3000:80 --address 0.0.0.0 > /dev/null 2>&1 &
	- kubectl port-forward <pod-name> 28015:27017
	
ingress:
	* kubectl get ing --all-namespaces
	* The Ingress "default" label must consist of lower case alphanumeric characters or '-', start with an alphabetic character, and end with an alphanumeric character (e.g. 'my-name',  or 'abc-123', regex used for validation is '[a-z]([-a-z0-9]*[a-z0-9])?'

ingress controller:
	kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.3.0/deploy/static/provider/cloud/deploy.yaml (k3d)
	nohup kubectl port-forward -n ingress-nginx service/ingress-nginx-controller 3000:80 --address 0.0.0.0  > /dev/null 2>&1 &
		* port forward to any ingress resource running in different namespaces, from common ingress controller running at port 80
		* service/ingress-nginx-controller  LoadBalancer   10.43.154.246   172.19.0.3    80:32497/TCP,443:31214/TCP   11m
		* Sample: (Two ingress resources are running in different namespace are invoked)
			curl -H "Host: go-demo-2.com" "http://0.0.0.0:3000/demo/hello"
			curl -H "Host: 2.0.go-demo-2.com" "http://0.0.0.0:3000/demo/hello"


formatting:
	kubectl exec -it docker -- docker image ls --format "{{.Repository}}"

Docker:
	- docker system prune -f (The docker system prune command removes all unused resources. At least, all those created and unused by Docker)
	- https://docs.docker.com/build/building/multi-stage/ 


Running deployement from stdin:
	cat volume/prometheus.yml | sed -e "s/192.168.99.100/$(minikube ip)/g" | kubectl create -f -  --record --save-config
	* Please note that, this time, the create command has dash (-) instead of the path to the file. Thatâ€™s an indication that stdin should be used instead.
	- kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.3.0/deploy/static/provider/cloud/deploy.yaml (k3d)
	- nohup kubectl port-forward -n ingress-nginx service/ingress-nginx-controller 3000:80 --address 0.0.0.0  > /dev/null 2>&1 &
	- kubectl get svc -n ingress-nginx
	- kubectl get pods -n ingress-nginx

Difference:
	apply vs create:
		- The apply command automatically saves the configuration so that we can edit it later on. The create command does not do such thing by default so we had to save it with --save-config.	